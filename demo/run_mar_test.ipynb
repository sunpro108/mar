{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "y9RUzQUWhZEV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/sunjinsheng/codebase/var_mar\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAR imports:\n",
    "import torch\n",
    "import numpy as np\n",
    "from models import mar\n",
    "from models.vae import AutoencoderKL\n",
    "from torchvision.utils import save_image\n",
    "from util import download\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from safetensors.torch import load_file\n",
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cpu\":\n",
    "    print(\"GPU not found. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "pe8NYbWBsvLl"
   },
   "source": [
    "# 1. Load and download pre-trained MAR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0EKkB_ssvLl"
   },
   "outputs": [],
   "source": [
    "model_type = \"mar_huge\" #@param [\"mar_base\", \"mar_large\", \"mar_huge\"]\n",
    "num_sampling_steps_diffloss = 100 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
    "if model_type == \"mar_base\":\n",
    "  # download.download_pretrained_marb(overwrite=False)\n",
    "  diffloss_d = 6\n",
    "  diffloss_w = 1024\n",
    "elif model_type == \"mar_large\":\n",
    "  # download.download_pretrained_marl(overwrite=False)\n",
    "  diffloss_d = 8\n",
    "  diffloss_w = 1280\n",
    "elif model_type == \"mar_huge\":\n",
    "  # download.download_pretrained_marh(overwrite=False)\n",
    "  diffloss_d = 12\n",
    "  diffloss_w = 1536\n",
    "else:\n",
    "  raise NotImplementedError\n",
    "model = mar.__dict__[model_type](\n",
    "  buffer_size=64,\n",
    "  diffloss_d=diffloss_d,\n",
    "  diffloss_w=diffloss_w,\n",
    "  num_sampling_steps=str(num_sampling_steps_diffloss)\n",
    ").to(device)\n",
    "vae = AutoencoderKL(embed_dim=16, ch_mult=(1, 1, 2, 2, 4), ckpt_path=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = load_file('checkpoints/mar-huge.safetensors', device='cuda')\n",
    "model.load_state_dict(ckpt)\n",
    "model.eval() # important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = load_file('checkpoints/kl16.safetensors', device='cuda')\n",
    "vae.load_state_dict(ckpt)\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JTNyzNZKb9E"
   },
   "source": [
    "# 3. Sample from Pre-trained MAR Models\n",
    "\n",
    "You can customize several sampling options. For the full list of ImageNet classes, [check out this](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "-Hw7B5h4Kk4p",
    "outputId": "4948292b-e1d2-4ce9-de75-e58cdd74f0c4"
   },
   "outputs": [],
   "source": [
    "# Set user inputs:\n",
    "seed = 0 #@param {type:\"number\"}\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "num_ar_steps = 64 #@param {type:\"slider\", min:1, max:256, step:1}\n",
    "cfg_scale = 4 #@param {type:\"slider\", min:1, max:10, step:0.1}\n",
    "cfg_schedule = \"constant\" #@param [\"linear\", \"constant\"]\n",
    "temperature = 1.0 #@param {type:\"slider\", min:0.9, max:1.1, step:0.01}\n",
    "class_labels = 207, 360, 388, 113, 355, 980, 323, 979 #@param {type:\"raw\"}\n",
    "samples_per_row = 4 #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.amp.autocast('cuda'):\n",
    "  sampled_tokens = model.sample_tokens(\n",
    "      bsz=len(class_labels), num_iter=num_ar_steps,\n",
    "      cfg=cfg_scale, cfg_schedule=cfg_schedule,\n",
    "      labels=torch.Tensor(class_labels).long().cuda(),\n",
    "      temperature=temperature, progress=True)\n",
    "  sampled_images = vae.decode(sampled_tokens / 0.2325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and display images:\n",
    "save_image(sampled_images, \"sample.png\", nrow=int(samples_per_row), normalize=True, value_range=(-1, 1))\n",
    "samples = Image.open(\"sample.png\")\n",
    "display(samples)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "s-p38t13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
